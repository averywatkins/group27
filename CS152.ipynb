{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBplQQagZeNI",
        "outputId": "57dbc5c9-8db0-4667-811d-dc526631a045"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully installed huggingface-hub-0.15.1 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ],
      "source": [
        "#!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "890HSAM1rAGi"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import sys\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKDTBM1OZkMk"
      },
      "outputs": [],
      "source": [
        "# Use BERT base uncased tokenizer and model, AdamW Optimizer with lr 1e-5\n",
        "# Read more: https://huggingface.co/bert-base-uncased\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in CSV dataset into 2 lists \"texts\" and \"labels\"\n",
        "\n",
        "def load_csv_dataset(csv_file):\n",
        "    csv.field_size_limit(sys.maxsize) # increase field size limit\n",
        "\n",
        "    texts, labels = [], []\n",
        "    with open(csv_file, 'r') as file:\n",
        "        csv_reader = csv.reader(file)\n",
        "        next(csv_reader)\n",
        "\n",
        "        for row in csv_reader:\n",
        "            try: # for first row only\n",
        "                text = row[0] \n",
        "                label = int(row[1])\n",
        "\n",
        "                if sys.getsizeof(text) > csv.field_size_limit(): continue # if field size exceeds limit, skip row\n",
        "\n",
        "                texts.append(text)\n",
        "                labels.append(int(label))\n",
        "\n",
        "            except csv.Error: continue  # if error in parsing, skip row\n",
        "\n",
        "    # print(\"Csv file:\", csv_file)\n",
        "    # print(\"Texts:\", texts[0:10])\n",
        "    # print(\"Labels:\", labels[0:10])\n",
        "\n",
        "    return texts, labels"
      ],
      "metadata": {
        "id": "iS3f3iMLPEm4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "v8rxDflSEFGG"
      },
      "outputs": [],
      "source": [
        "# Read in train and test datasets, split train into train and dev datasets\n",
        "\n",
        "train_csv = 'labels.csv'\n",
        "test_csv = 'test_labels.csv'\n",
        "\n",
        "train_texts, train_labels = load_csv_dataset(train_csv)\n",
        "test_texts, test_labels = load_csv_dataset(test_csv)\n",
        "\n",
        "train_texts, dev_texts, train_labels, dev_labels = train_test_split(train_texts, train_labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Data #\n",
        "# Note: this example data is not of the domain of interest; GPT-generated data of \"suspicious vs innocent\" statements.\n",
        "# (Data below is not suspicious in the way that our bot defines, I know)\n",
        "\"\"\"\n",
        "train_texts = [\n",
        "    \"I saw a cute puppy today!\",\n",
        "    \"This restaurant serves delicious food.\",\n",
        "    \"Be careful while walking alone at night.\",\n",
        "    \"The new movie is getting great reviews.\",\n",
        "    \"Please avoid sharing personal information online.\"\n",
        "]\n",
        "\n",
        "train_labels = [0, 0, 1, 0, 1]\n",
        "\n",
        "test_texts = [\n",
        "    \"I received a suspicious email today.\",\n",
        "    \"The weather is beautiful outside.\",\n",
        "    \"Always verify the authenticity of online sellers.\",\n",
        "    \"The concert was amazing!\",\n",
        "    \"Don't share your passwords with anyone.\"\n",
        "]\n",
        "\n",
        "test_labels = [1, 0, 1, 0, 1]\n",
        "\n",
        "dev_texts = [\n",
        "    \"Exercise regularly for a healthy lifestyle.\",\n",
        "    \"Check the reviews before making an online purchase.\",\n",
        "    \"Never disclose sensitive information over the phone.\",\n",
        "    \"Explore new cuisines and try unique dishes.\",\n",
        "    \"Ensure your passwords are strong and secure.\"\n",
        "]\n",
        "\n",
        "dev_labels = [0, 0, 1, 0, 1]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "yKzvUmiIQBrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "iaQIwBff60wY"
      },
      "outputs": [],
      "source": [
        "# Shuffle train and test datasets randomly, create TextDataset\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.texts[index], self.labels[index]\n",
        "### Train\n",
        "# Shuffle train\n",
        "combined_data = list(zip(train_texts, train_labels))\n",
        "random.shuffle(combined_data)\n",
        "train_texts, train_labels = zip(*combined_data)\n",
        "\n",
        "# Create train_loader\n",
        "train_dataset = TextDataset(train_texts, train_labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "### Dev\n",
        "# Shuffle dev\n",
        "combined_data = list(zip(dev_texts, dev_labels))\n",
        "random.shuffle(combined_data)\n",
        "dev_texts, dev_labels = zip(*combined_data)\n",
        "\n",
        "# Create dev_loader\n",
        "dev_dataset = TextDataset(dev_texts, dev_labels)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "### Test\n",
        "# Shuffle test\n",
        "combined_data = list(zip(test_texts, test_labels))\n",
        "random.shuffle(combined_data)\n",
        "test_texts, test_labels = zip(*combined_data)\n",
        "\n",
        "# Create test_loader\n",
        "test_dataset = TextDataset(test_texts, test_labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that evaluates model with data (either dev or test set)\n",
        "\n",
        "def model_eval(testdev_loader, model, device):\n",
        "    model.eval()\n",
        "\n",
        "    val_predictions = []\n",
        "    val_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(testdev_loader, desc=\"Validation\", leave=True)\n",
        "        for texts, labels in pbar:\n",
        "            texts = list(texts)\n",
        "            labels = list(labels)\n",
        "            encoded_inputs = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
        "            input_ids = encoded_inputs['input_ids'].to(device)\n",
        "            attention_mask = encoded_inputs['attention_mask'].to(device)\n",
        "            labels = torch.tensor(labels).to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "            val_predictions.extend(predictions.cpu().numpy())\n",
        "            val_targets.extend(labels.cpu().numpy())\n",
        "\n",
        "    return val_predictions, val_targets"
      ],
      "metadata": {
        "id": "3JNo8PFxgzVM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to save model to specified filepath\n",
        "def save_model(model, optimizer, filepath):\n",
        "    save_info = {\n",
        "        'model': model.state_dict()\n",
        "    }\n",
        "\n",
        "    torch.save(save_info, filepath)\n",
        "    print(f\"Saved the model to {filepath}\")"
      ],
      "metadata": {
        "id": "lQ7wq4ulVivT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "f9wSknnW7acb"
      },
      "outputs": [],
      "source": [
        "# Function to finetune model\n",
        "def train(train_loader, model, device, optimizer, tokenizer, num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    best_dev_acc = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True) \n",
        "        for texts, labels in pbar:\n",
        "            texts = list(texts)\n",
        "            labels = list(labels)\n",
        "            encoded_inputs = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
        "            input_ids = encoded_inputs['input_ids'].to(device)\n",
        "            attention_mask = encoded_inputs['attention_mask'].to(device)\n",
        "            labels = torch.tensor(labels).to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.set_postfix({'Loss': loss.item()})\n",
        "        \n",
        "        val_predictions, val_targets = model_eval(dev_loader, model, device)\n",
        "        dev_acc = accuracy_score(val_targets, val_predictions)\n",
        "        print(f\"Epoch {epoch + 1}: dev acc :: {dev_acc :.3f}\")\n",
        "\n",
        "        if dev_acc > best_dev_acc: # save best model based on dev dataset\n",
        "            best_dev_acc = dev_acc\n",
        "            save_model(model, optimizer, 'best_model.pt')\n",
        "    \n",
        "    # save last model\n",
        "    save_model(model, optimizer, 'last_model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model, num_epochs = 5, batch_size = 32, lr = 1e-5\n",
        "train(train_loader, model, device, optimizer, tokenizer, num_epochs=5)"
      ],
      "metadata": {
        "id": "JKR5NDFIQ6mH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate preds for given data (either dev or test set), batch_size = 32\n",
        "val_predictions, val_targets = model_eval(test_loader, model, device)"
      ],
      "metadata": {
        "id": "TEvCztNHNqAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVPf2Zcd9BQc"
      },
      "outputs": [],
      "source": [
        "# Evaluate test set on accuracy, precision, recall, and F1\n",
        "\n",
        "accuracy = accuracy_score(val_targets, val_predictions)\n",
        "precision = precision_score(val_targets, val_predictions)\n",
        "recall = recall_score(val_targets, val_predictions)\n",
        "f1 = f1_score(val_targets, val_predictions)\n",
        "\n",
        "print(f\"Validation Accuracy: {accuracy}\")\n",
        "print(f\"Validation Precision: {precision}\")\n",
        "print(f\"Validation Recall: {recall}\")\n",
        "print(f\"Validation F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vQ4NFVDx9auO"
      },
      "outputs": [],
      "source": [
        "# Inference (for integration with Bot)\n",
        "\n",
        "def predict_text(text):\n",
        "    # load saved model\n",
        "    model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "    #checkpoint = torch.load('best_model.pt')\n",
        "    checkpoint = torch.load('test_model.pt')\n",
        "    model.load_state_dict(checkpoint['model'])\n",
        "    model.to(device)\n",
        "\n",
        "    # do prediction steps\n",
        "    encoded_inputs = tokenizer([text], padding=True, truncation=True, return_tensors='pt')\n",
        "    input_ids = encoded_inputs['input_ids'].to(device)\n",
        "    attention_mask = encoded_inputs['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "    predicted_label = predictions.item()\n",
        "    return predicted_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fQ8jHUt9ceK"
      },
      "outputs": [],
      "source": [
        "# Testing inference\n",
        "\"\"\"\n",
        "example_texts = [\"The weather is so sunny today!\",\n",
        "                 \"Make sure all your accounts are secure.\"]\n",
        "\n",
        "predictions = [predict_text(text) for text in example_texts]\n",
        "\n",
        "for text, prediction in zip(example_texts, predictions):\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Predicted label: {prediction}\")\n",
        "    print()\n",
        "\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1jylTE5pEo3L6JydIXKPRe0WnaEq-SrKL",
      "authorship_tag": "ABX9TyMh2+mwtUb3D7U7BuAHZPpa"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}